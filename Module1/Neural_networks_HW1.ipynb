{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 1"
      ],
      "metadata": {
        "id": "kaqAxu3neLLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импортирование необходимых библиотек"
      ],
      "metadata": {
        "id": "9kd8kA9keZfl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tkcu90oGos5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from glob import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms as T\n",
        "from tensorflow import summary as tfsummary\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Чтение тренировочной и тестовой выборки"
      ],
      "metadata": {
        "id": "WXCes5Qxggy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструкция для скачивания и загрузки фотографий в Сolab находится в github"
      ],
      "metadata": {
        "id": "WsGPueHogtRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heigth_width = 32\n",
        "\n",
        "CLASSES = ['Тираннозавр', 'Мозазавр', 'Птеранодон'] # Здесь требуется указать ваши классы\n",
        "\n",
        "images = []\n",
        "images_t = []\n",
        "classes = []\n",
        "classes_t = []\n",
        "\n",
        "for CLASS in range(0, len(CLASSES)):\n",
        "  path_class_1 = \"/content/%s/*.*\"%CLASSES[CLASS]\n",
        "  i=0\n",
        "  for photo in glob(path_class_1):\n",
        "      i+=1\n",
        "      img = Image.open(photo).convert('RGB')\n",
        "      img = img.resize((heigth_width, heigth_width), Image.ANTIALIAS)\n",
        "      if i > int(len(os.listdir(\"/content/%s/\"%CLASSES[CLASS]))*0.8):\n",
        "          images_t.append(np.asarray(img))\n",
        "          classes_t.append(np.asarray(CLASS))\n",
        "      else:\n",
        "          images.append(np.asarray(img))\n",
        "          classes.append(np.asarray(CLASS))\n",
        "\n",
        "\n",
        "train_X = np.array(images)\n",
        "train_y = np.array(classes)\n",
        "\n",
        "test_X = np.array(images_t)\n",
        "test_y = np.array(classes_t)\n",
        "Image.fromarray(train_X[123]).resize((512,512))"
      ],
      "metadata": {
        "id": "3_ZUbtHgWc3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "9904439b-181d-46df-acc3-138f78779311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3d053690868d>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 123 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarDataset(Dataset):\n",
        "     def __init__(self, X, y, transform=None, p=0.0):\n",
        "         assert X.size(0) == y.size(0)\n",
        "         super(Dataset, self).__init__()\n",
        "         self.X = X\n",
        "         self.y = y\n",
        "         self.transform = transform\n",
        "         self.prob = p\n",
        "\n",
        "     def __len__(self):\n",
        "         return self.y.size(0)\n",
        "\n",
        "     def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        if self.transform and np.random.random()<self.prob:\n",
        "            x = self.transform(x.permute(2, 0, 1)/255.).permute(1, 2, 0)*255.\n",
        "        y = self.y[index]\n",
        "        return x, y\n",
        "\n",
        "transform = T.Compose([\n",
        "     T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
        "     T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2),\n",
        "                    shear=5),\n",
        "])\n",
        "\n",
        "Image.fromarray((transform(torch.Tensor(train_X[50]).permute(2, 0, 1)/255.).\\\n",
        "                 permute(1, 2, 0).numpy()*255.).astype(np.uint8)).\\\n",
        "                 resize((256, 256))"
      ],
      "metadata": {
        "id": "y2QyEwFlJoE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-mpk0Ex7E6Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "aefAwNJrGeBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Приведение фотографий к требуемому размеру"
      ],
      "metadata": {
        "id": "o2DLReuahANV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание Pytorch DataLoader'a"
      ],
      "metadata": {
        "id": "YuBJ34bmhUR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "dataloader = {}\n",
        "for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
        "                        ['train', 'test']):\n",
        "    tensor_x = torch.Tensor(X)\n",
        "    tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
        "                                     num_classes=len(CLASSES))/1.\n",
        "    dataset = TensorDataset(tensor_x, tensor_y) # создание объекта датасета\n",
        "    dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True) # создание экземпляра класса DataLoader\n",
        "dataloader"
      ],
      "metadata": {
        "id": "dnVQ5m0kY2Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание Pytorch модели многослойного перцептрона с одним скрытым слоем"
      ],
      "metadata": {
        "id": "OXG8kHNjhfuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.tensor(mean).to(device)\n",
        "        self.std = torch.tensor(std).to(device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input / 255.0\n",
        "        x = x - self.mean\n",
        "        x = x / self.std\n",
        "        return x.permute(0, 3, 1, 2) # nhwc -> nm\n",
        "\n",
        "class GlobalMaxPool2d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalMaxPool2d, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = F.adaptive_max_pool2d(input, output_size=1)\n",
        "        return out.flatten(start_dim=1)\n",
        "\n",
        "class Cifar100_MLP(nn.Module):\n",
        "    def __init__(self, hidden_size=32, classes=100):\n",
        "        super(Cifar100_MLP, self).__init__()\n",
        "        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
        "        self.seq = nn.Sequential(\n",
        "            Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025]),\n",
        "            # первый способ уменьшения размерности картинки - через stride\n",
        "            nn.Conv2d(3, HIDDEN_SIZE, 3, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "            # второй способ уменьшения размерности картинки - через слой пуллинг\n",
        "            nn.Conv2d(HIDDEN_SIZE, HIDDEN_SIZE*2, 3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(4),#nn.MaxPool2d(4),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(HIDDEN_SIZE*8, classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.seq(input)\n",
        "\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
        "                       'cifar100_resnet20',\n",
        "                       #\"cifar100_mobilenetv2_x0_5\",\n",
        "                       pretrained=True)\n",
        "model.to(device)\n",
        "new_model = nn.Sequential(\n",
        "    Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025]),# https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
        "    model\n",
        ").to(device)\n",
        "print(new_model(torch.rand(1, 32, 32, 3).to(device)))\n",
        "summary(new_model, input_size=(32, 32, 3))\n",
        "new_model"
      ],
      "metadata": {
        "id": "Dtld1amNY9lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(3, 512, 512))"
      ],
      "metadata": {
        "id": "hlDHowgpHAXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/Fangyh09/pytorch-receptive-field.git\n",
        "def compute_RF_numerical(net,img_np):\n",
        "    '''\n",
        "    @param net: Pytorch network\n",
        "    @param img_np: numpy array to use as input to the networks, it must be full of ones and with the correct\n",
        "    shape.\n",
        "    '''\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.fill_(0)\n",
        "    #net.apply(weights_init)\n",
        "    img_ = torch.tensor(torch.from_numpy(img_np).float(),requires_grad=True)\n",
        "    out_cnn=net(img_.to(device))\n",
        "    out_shape=out_cnn.size()\n",
        "    ndims=len(out_cnn.size())\n",
        "    grad=torch.zeros(out_cnn.size())\n",
        "    l_tmp=[]\n",
        "    for i in range(ndims):\n",
        "        if i==0 or i ==1:#batch or channel\n",
        "            l_tmp.append(0)\n",
        "        else:\n",
        "            l_tmp.append(out_shape[i]/2)\n",
        "\n",
        "    grad[tuple(l_tmp)]=1\n",
        "    out_cnn.backward(gradient=grad.to(device))\n",
        "    grad_np=img_.grad[0,0].data.detach().cpu().numpy()\n",
        "    idx_nonzeros=np.where(grad_np!=0)\n",
        "    RF=[np.max(idx)-np.min(idx)+1 for idx in idx_nonzeros]\n",
        "\n",
        "    return RF\n",
        "\n",
        "compute_RF_numerical(model, np.zeros((1, 3, 1024, 1024)))"
      ],
      "metadata": {
        "id": "8ah8v0XuHElS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## resnet20\n",
        "in_features = new_model[1].fc.in_features\n",
        "new_model[1].fc = nn.Linear(in_features=in_features,\n",
        "                            out_features=len(CLASSES),\n",
        "                            bias=True)\n",
        "\n",
        "new_model.to(device)\n",
        "summary(new_model, input_size=(32, 32, 3))\n",
        "print(new_model(torch.rand(1, 32, 32, 3).to(device)))"
      ],
      "metadata": {
        "id": "u-6-x-QHHdLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Обучаемые параметры:\")\n",
        "keep_last = 2\n",
        "total = len([*new_model.named_parameters()])\n",
        "params_to_update = []\n",
        "for i, (name, param) in enumerate(new_model.named_parameters()):\n",
        "    if i < total - keep_last:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)\n",
        "summary(new_model, input_size=(32, 32, 3))\n"
      ],
      "metadata": {
        "id": "D8stU4KqH1Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем сглаживание целевых меток, это увеличит значение функции потерь\n",
        "# но полученная модель будет более устойчивой к выбросам в обучающей выборке\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# используется SGD c momentum и L2-регуляризацией весов\n",
        "optimizer = optim.SGD(params_to_update, lr=4e-4, momentum=0.9,\n",
        "                      weight_decay=1e-7)\n",
        "# добавляем постепенное уменьшение шага обучения каждые 200 эпох\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
      ],
      "metadata": {
        "id": "IWQm7dyKIVrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 120\n",
        "REDRAW_EVERY = 10\n",
        "steps_per_epoch = len(dataloader['train'])\n",
        "steps_per_epoch_val = len(dataloader['test'])\n",
        "# NEW\n",
        "pbar = tqdm(total=EPOCHS*steps_per_epoch)\n",
        "losses = []\n",
        "losses_val = []\n",
        "passed = 0\n",
        "# для создания чекпоинта\n",
        "best_acc = 0\n",
        "checkpoint_path = 'cifar_cnn_fine.pth'\n",
        "for epoch in range(EPOCHS):  # проход по набору данных несколько раз\n",
        "    tmp = []\n",
        "    new_model.train()\n",
        "    for i, batch in enumerate(dataloader['train'], 0):\n",
        "        # получение одного минибатча; batch это двуэлементный список из [inputs, labels]\n",
        "        inputs, labels = batch\n",
        "        # на GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # очищение прошлых градиентов с прошлой итерации\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # прямой + обратный проходы + оптимизация\n",
        "        outputs = new_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        #loss = F.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # для подсчёта статистик\n",
        "        accuracy = (labels.detach().argmax(dim=-1)==outputs.detach().argmax(dim=-1)).\\\n",
        "                    to(torch.float32).mean().cpu()*100\n",
        "        tmp.append((loss.item(), accuracy.item()))\n",
        "        pbar.update(1)\n",
        "    losses.append((np.mean(tmp, axis=0),\n",
        "                   np.percentile(tmp, 25, axis=0),\n",
        "                   np.percentile(tmp, 75, axis=0)))\n",
        "    scheduler.step() # обновляем learning_rate каждую эпоху\n",
        "    tmp = []\n",
        "    new_model.eval()\n",
        "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
        "        for i, data in enumerate(dataloader['test'], 0):\n",
        "            inputs, labels = data\n",
        "            # на GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = new_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            accuracy = (labels.argmax(dim=-1)==outputs.argmax(dim=-1)).\\\n",
        "                        to(torch.float32).mean().cpu()*100\n",
        "            tmp.append((loss.item(), accuracy.item()))\n",
        "    losses_val.append((np.mean(tmp, axis=0),\n",
        "                       np.percentile(tmp, 25, axis=0),\n",
        "                       np.percentile(tmp, 75, axis=0)))\n",
        "    # сохранение чекпоинта\n",
        "    acc = losses_val[-1][0][1]\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(new_model.state_dict(), checkpoint_path)\n",
        "    # обновление графиков\n",
        "    if (epoch+1) % REDRAW_EVERY != 0:\n",
        "        continue\n",
        "    clear_output(wait=False)\n",
        "    print('Эпоха: %s\\n'\n",
        "          'Лучшая доля правильных ответов: %s\\n'\n",
        "          'Текущая доля правильных ответов: %s' % (epoch+1, best_acc, acc))\n",
        "    passed += pbar.format_dict['elapsed']\n",
        "    pbar = tqdm(total=EPOCHS*steps_per_epoch, miniters=5)\n",
        "    pbar.update((epoch+1)*steps_per_epoch)\n",
        "    x_vals = np.arange(epoch+1)\n",
        "    _, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    stats = np.array(losses)\n",
        "    stats_val = np.array(losses_val)\n",
        "    ax[1].set_ylim(stats_val[:, 0, 1].min()-5, 100)\n",
        "    ax[1].grid(axis='y')\n",
        "    for i, title in enumerate(['CCE', 'Accuracy']):\n",
        "        ax[i].plot(x_vals, stats[:, 0, i], label='train')\n",
        "        ax[i].fill_between(x_vals, stats[:, 1, i],\n",
        "                           stats[:, 2, i], alpha=0.4)\n",
        "        ax[i].plot(x_vals, stats_val[:, 0, i], label='val')\n",
        "        ax[i].fill_between(x_vals,\n",
        "                           stats_val[:, 1, i],\n",
        "                           stats_val[:, 2, i], alpha=0.4)\n",
        "        ax[i].legend()\n",
        "        ax[i].set_title(title)\n",
        "    plt.show()\n",
        "new_model.load_state_dict(torch.load(checkpoint_path))\n",
        "print('Обучение закончено за %s секунд' % passed)"
      ],
      "metadata": {
        "id": "BWJC5ZajIbHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "dataloader = {}\n",
        "for (X, y), part in zip([(train_X, train_y), (test_X, test_y)],\n",
        "                        ['train', 'test']):\n",
        "    tensor_x = torch.Tensor(X)\n",
        "    tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),\n",
        "                                     num_classes=len(CLASSES))/1.\n",
        "    dataset = CifarDataset(tensor_x, tensor_y,\n",
        "                           transform=None,\n",
        "                           p=0.0) # создание объекта датасета\n",
        "    dataloader[part] = DataLoader(dataset, batch_size=batch_size,\n",
        "                                  num_workers=2, shuffle=True) # создание экземпляра класса DataLoader\n",
        "dataloader"
      ],
      "metadata": {
        "id": "KX5S-wmuKHzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for part in ['train', 'test']:\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
        "        for i, data in enumerate(dataloader[part], 0):\n",
        "            inputs, labels = data\n",
        "             # на GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = new_model(inputs).detach().cpu().numpy()\n",
        "            y_pred.append(outputs)\n",
        "            y_true.append(labels.cpu().numpy())\n",
        "        y_true = np.concatenate(y_true)\n",
        "        y_pred = np.concatenate(y_pred)\n",
        "        print(part)\n",
        "        print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1),\n",
        "                                    digits=4, target_names=list(map(str, CLASSES))))\n",
        "        print('-'*50)"
      ],
      "metadata": {
        "id": "pPP8OTeRKU2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Сохранение модели в ONNX"
      ],
      "metadata": {
        "id": "gGv5L6lMiMP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраниение модели\n",
        "# ПЕРВЫЙ СПОСОБ: сохранение параметров\n",
        "PATH = 'cifar_cnn_fine.pth'\n",
        "torch.save(new_model.state_dict(), PATH)\n",
        "\n",
        "# ВТОРОЙ СПОСОБ: сохранение всей архитектуры\n",
        "PATH2 = 'cifar_cnn_fine.pt'\n",
        "torch.save(new_model, PATH2)\n",
        "# загрузка\n",
        "new_model_2 = torch.load(PATH2)\n",
        "new_model_2.eval()"
      ],
      "metadata": {
        "id": "MvWbYlrxZpG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalAvgPooling2d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalAvgPooling2d, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        return torch.flatten(x, 1)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, model):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        # Here you get the bottleneck/feature extractor\n",
        "        self.normalization = model[0]\n",
        "        self.resnet_feature_extractor = \\\n",
        "                nn.Sequential(*list(model[1].children())[:-1])\n",
        "\n",
        "        # Now you can include your classifiers\n",
        "        self.classifier = list(model[1].children())[-1]\n",
        "\n",
        "    # Set your own forward pass\n",
        "    def forward(self, x, extra_info=None):\n",
        "        x = self.normalization(x)\n",
        "        x = self.resnet_feature_extractor(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "new_model = torch.load(PATH2)\n",
        "new_model[1].avgpool = GlobalAvgPooling2d()\n",
        "new_model.to(device)\n",
        "model = MyModel(new_model).to(device)\n",
        "\n",
        "summary(model, input_size=(32, 32, 3))"
      ],
      "metadata": {
        "id": "0YkTyTTteUJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# входной тензор для модели\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.randn(1, 32, 32, 3, requires_grad=True).to(device)\n",
        "torch_out = model(x)\n",
        "\n",
        "# экспорт модели\n",
        "torch.onnx.export(model,               # модель\n",
        "                  x,                   # входной тензор (или кортеж нескольких тензоров)\n",
        "                  \"cifar100.onnx\", # куда сохранить (либо путь к файлу либо fileObject)\n",
        "                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели\n",
        "                  opset_version=9,     # версия ONNX\n",
        "                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации\n",
        "                  input_names = ['input'],   # имя входного слоя\n",
        "                  output_names = ['output'],  # имя выходного слоя\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # динамичные оси, в данном случае только размер пакета\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "3ZWLRj21Zq44"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}